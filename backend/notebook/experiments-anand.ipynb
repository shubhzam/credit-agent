{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### main testing file###\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, Dict, Any\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AIMessage\n",
    "import requests\n",
    "import time\n",
    "import pyodbc\n",
    "from contextlib import closing\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    conn_str = (\n",
    "        \"DRIVER={SQL Server};\"\n",
    "        \"SERVER=216.48.191.98;\"\n",
    "        \"DATABASE=Agentic_Automation;\"\n",
    "        \"UID=ibsadmin;\"\n",
    "        \"PWD=Viking@@ibs2023;\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_number_list=['11']\n",
      "dependecy_task_number=[None]\n",
      "==============\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def task_insertion(work_id,webtop_id,process_name,task_name):\n",
    "    conn=pyodbc.connect(config.conn_str)\n",
    "    cur=conn.cursor()\n",
    "    task_master_data=pd.read_sql(f'''select tm.*,td.Dependency_Task_Number from Credit_GPT.dbo.Task_master as tm left join Credit_GPT.dbo.[Task_Dependencies] as td \n",
    "                                 on tm.Task_Number=td.Task_Number where tm.Process_Name='{process_name}'\n",
    "                                  ''',conn)\n",
    "    task_number_list=[]\n",
    "    cr=0\n",
    "    # print(task_master_data)\n",
    "\n",
    "    while True:\n",
    "        cr+=1\n",
    "        if cr==1:\n",
    "            task_number=task_master_data[task_master_data[\"Task_Name\"]==task_name & task_master_data[\"Process_Name\"] == process_name][\"Task_Number\"]\n",
    "            dependecy_task_number=task_master_data[task_master_data[\"Task_Name\"]==task_name & task_master_data[\"Process_Name\"] == process_name][\"Dependency_Task_Number\"]\n",
    "        else:\n",
    "            task_number=task_master_data[task_master_data[\"Task_Number\"].isin(dependecy_task_number)][\"Task_Number\"]\n",
    "            dependecy_task_number=task_master_data[task_master_data[\"Task_Number\"].isin(dependecy_task_number)][\"Dependency_Task_Number\"]\n",
    "\n",
    "        task_number_list.extend(list(set(task_number)))\n",
    "        print(f\"task_number_list={task_number_list}\\ndependecy_task_number={list(dependecy_task_number)}\\n==============\")\n",
    "        if dependecy_task_number.empty:\n",
    "            break\n",
    "        elif dependecy_task_number.iloc[0] == None and len(dependecy_task_number)==1:\n",
    "            break\n",
    "    sTask_number_list=\"'\"+\"','\".join(task_number_list)+\"'\"\n",
    "\n",
    "    Already_present_records=pd.read_sql(f'''select Task_Number from Credit_GPT.dbo.Task_Processing where Webtop_ID='{webtop_id}' and \n",
    "                                        Task_Number in ({sTask_number_list})''',conn)\n",
    "    set_Already_present_records=set(Already_present_records['Task_Number'])\n",
    "    set_task_number_list=set(task_number_list)\n",
    "    set_new_tasks_to_insert=set_task_number_list-set_Already_present_records\n",
    "    sNew_tasks_to_insert=\"'\"+\"','\".join(set_new_tasks_to_insert)+\"'\"\n",
    "    cur.execute(f'''Insert Into Credit_GPT.dbo.Task_Processing \n",
    "                    select '{work_id}','{webtop_id}', Task_Number,Task_Name ,'New',getdate(),Null,Null,0,Null,Null,'{process_name}'\n",
    "                    from Credit_GPT.dbo.Task_Master where Task_Number in ({sNew_tasks_to_insert})\n",
    "                ''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    # return task_number_list,set_Already_present_records,set_new_tasks_to_insert,\n",
    "\n",
    "print(task_insertion('work310','074PZ8600310','Bureau Demog','ReportCreation'))\n",
    "# 349PZ8633504\n",
    "# Bureau Analysis\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define the shape of the pipeline state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    data: Dict[str, Any]\n",
    " \n",
    "# 2) Your two Power Automate endpoints\n",
    "FLOWS = {\n",
    "    \"insertion_in_db\": \"https://prod-02.centralindia.logic.azure.com:443/workflows/176b9969d13147aa90ae97d9b53c7ca9/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=cRltkx9lLIr5KRfxpNBvPZcmp2ybs3uxpSM_EvYk42s\",\n",
    "    \"doc_download\": \"https://prod-16.centralindia.logic.azure.com:443/workflows/e8c18012e313410dae07e6ed20ccc816/triggers/manual/paths/invoke?api-version=2016-06-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=oMl04_zC72XGN8W-ChrED9jW4pvSs5xUEQQA0BuHs3E\"\n",
    "}\n",
    " \n",
    "def call_flow(flow_name: str, data: dict) -> dict:\n",
    "    \"\"\"Trigger a Power Automate flow and report success/failure.\"\"\"\n",
    "    try:\n",
    "        resp = requests.post(FLOWS[flow_name], json=data)\n",
    "        resp.raise_for_status()\n",
    "        return {\"success\": True}\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    " \n",
    "def insertion_in_db(state: State) -> State:\n",
    "    result = call_flow(\"insertion_in_db\", state[\"data\"])\n",
    "    print(f\"DB insertion result: {result}\")\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(f\"DB insertion: {'✅' if result['success'] else '❌'}\")\n",
    "        ],\n",
    "        \"data\": state[\"data\"]\n",
    "    }\n",
    " \n",
    "def wait_for_status_dbinsertion(state: State) -> State:\n",
    "    \"\"\"Poll the workflow_status table until status == 'Completed'.\"\"\"\n",
    "    conn_str = (\n",
    "        \"DRIVER={SQL Server};\"\n",
    "        \"SERVER=216.48.191.98;\"\n",
    "        \"DATABASE=Agentic_Automation;\"\n",
    "        \"UID=ibsadmin;\"\n",
    "        \"PWD=Viking@@ibs2023;\"\n",
    "    )\n",
    "    query = \"\"\"\n",
    "        SELECT DbInsertion\n",
    "        FROM [Agentic_Automation].[dbo].[workflow_status]\n",
    "        WHERE WebtopId = ?\n",
    "    \"\"\"\n",
    "    webtop_id = state[\"data\"][\"WebtopId\"]\n",
    " \n",
    "    with pyodbc.connect(conn_str, autocommit=True) as conn:\n",
    "        with closing(conn.cursor()) as cur:\n",
    "            while True:\n",
    "                cur.execute(query, webtop_id)\n",
    "                row = cur.fetchone()\n",
    "                if row and row[0] == \"Completed\":\n",
    "                    break\n",
    "                time.sleep(5)\n",
    "    print(\"DB status: Completed\")\n",
    "    return {\n",
    "        \"messages\": [AIMessage(\"DB status: ✅ Completed\")],\n",
    "        \"data\": state[\"data\"]\n",
    "    }\n",
    " \n",
    "def wait_for_status_docdownload(state: State) -> State:\n",
    "    \"\"\"Poll the workflow_status table until status == 'Completed'.\"\"\"\n",
    "    conn_str = (\n",
    "        \"DRIVER={SQL Server};\"\n",
    "        \"SERVER=216.48.191.98;\"\n",
    "        \"DATABASE=Agentic_Automation;\"\n",
    "        \"UID=ibsadmin;\"\n",
    "        \"PWD=Viking@@ibs2023;\"\n",
    "    )\n",
    "    query = \"\"\"\n",
    "        SELECT DocDownload\n",
    "        FROM [Agentic_Automation].[dbo].[workflow_status]\n",
    "        WHERE WebtopId = ?\n",
    "    \"\"\"\n",
    "    webtop_id = state[\"data\"][\"WebtopId\"]\n",
    " \n",
    "    with pyodbc.connect(conn_str, autocommit=True) as conn:\n",
    "        with closing(conn.cursor()) as cur:\n",
    "            while True:\n",
    "                cur.execute(query, webtop_id)\n",
    "                row = cur.fetchone()\n",
    "                if row and row[0] == \"Completed\":\n",
    "                    break\n",
    "                time.sleep(5)\n",
    "    print(\"Doc download status: Completed\")\n",
    " \n",
    "    return {\n",
    "        \"messages\": [AIMessage(\"DB status: ✅ Completed\")],\n",
    "        \"data\": state[\"data\"]\n",
    "    }\n",
    " \n",
    " \n",
    " \n",
    "def doc_download(state: State) -> State:\n",
    "    result = call_flow(\"doc_download\", state[\"data\"])\n",
    "    print(f\"Document download result: {result}\")\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(f\"Document download: {'✅' if result['success'] else '❌'}\")\n",
    "        ],\n",
    "        \"data\": {**state[\"data\"], \"doc_result\": result}\n",
    "    }\n",
    " \n",
    "def create_pipeline():\n",
    "    graph = StateGraph(State)\n",
    "    graph.add_node(\"insertion_in_db\", insertion_in_db)\n",
    "    graph.add_node(\"wait_for_status_dbinsertion\",  wait_for_status_dbinsertion)\n",
    "    graph.add_node(\"doc_download\",     doc_download)\n",
    "    graph.add_node(\"wait_for_status_docdownload\", wait_for_status_docdownload)\n",
    " \n",
    "    graph.set_entry_point(\"insertion_in_db\")\n",
    "    graph.add_edge(\"insertion_in_db\", \"wait_for_status_dbinsertion\")\n",
    "    graph.add_edge(\"wait_for_status_dbinsertion\", \"doc_download\")\n",
    "    graph.add_edge(\"doc_download\", \"wait_for_status_docdownload\")\n",
    "    graph.add_edge(\"wait_for_status_docdownload\", END)\n",
    " \n",
    "    return graph.compile()\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = create_pipeline()\n",
    "    # seed the pipeline with an ID of your workflow run\n",
    "    result = pipeline.invoke({\n",
    "        \"messages\": [],\n",
    "        \"data\": {\"WebtopId\": \"ABC123\"}\n",
    "    })\n",
    "    print(\"Pipeline completed, messages:\")\n",
    "    for msg in result[\"messages\"]:\n",
    "        print(\" •\", msg.content)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_number_list=['5']\n",
      "dependecy_task_number=['4']\n",
      "==============\n",
      "task_number_list=['5', '4']\n",
      "dependecy_task_number=['1', '3']\n",
      "==============\n",
      "task_number_list=['5', '4', '3', '1']\n",
      "dependecy_task_number=[None, '2']\n",
      "==============\n",
      "task_number_list=['5', '4', '3', '1', '2']\n",
      "dependecy_task_number=[None]\n",
      "==============\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#### main testing file###\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from typing import Annotated, Dict, Any\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "import requests\n",
    "\n",
    "import time\n",
    "\n",
    "import pyodbc\n",
    "\n",
    "from contextlib import closing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    " \n",
    "class config:\n",
    "\n",
    "    conn_str = (\n",
    "\n",
    "        \"DRIVER={SQL Server};\"\n",
    "\n",
    "        \"SERVER=216.48.191.98;\"\n",
    "\n",
    "        \"DATABASE=Agentic_Automation;\"\n",
    "\n",
    "        \"UID=ibsadmin;\"\n",
    "\n",
    "        \"PWD=Viking@@ibs2023;\"\n",
    "\n",
    "    )\n",
    "\n",
    "def task_insertion(work_id,webtop_id,process_name,task_name):\n",
    "\n",
    "    conn=pyodbc.connect(config.conn_str)\n",
    "\n",
    "    cur=conn.cursor()\n",
    "\n",
    "    task_master_data=pd.read_sql(f'''select tm.*,td.Dependency_Task_Number from Credit_GPT.dbo.Task_master as tm left join Credit_GPT.dbo.[Task_Dependencies] as td \n",
    "\n",
    "                                 on tm.Task_Number=td.Task_Number where tm.Process_Name='{process_name}'\n",
    "\n",
    "                                  ''',conn)\n",
    "\n",
    "    task_number_list=[]\n",
    "\n",
    "    cr=0\n",
    "\n",
    "    # print(task_master_data)\n",
    " \n",
    "    while True:\n",
    "\n",
    "        cr+=1\n",
    "\n",
    "        if cr==1:\n",
    "\n",
    "            task_number=task_master_data[task_master_data[\"Task_Name\"]==task_name][\"Task_Number\"]\n",
    "\n",
    "            dependecy_task_number=task_master_data[task_master_data[\"Task_Name\"]==task_name][\"Dependency_Task_Number\"]\n",
    "\n",
    "        else:\n",
    "\n",
    "            task_number=task_master_data[task_master_data[\"Task_Number\"].isin(dependecy_task_number)][\"Task_Number\"]\n",
    "\n",
    "            dependecy_task_number=task_master_data[task_master_data[\"Task_Number\"].isin(dependecy_task_number)][\"Dependency_Task_Number\"]\n",
    " \n",
    "        task_number_list.extend(list(set(task_number)))\n",
    "\n",
    "        print(f\"task_number_list={task_number_list}\\ndependecy_task_number={list(dependecy_task_number)}\\n==============\")\n",
    "\n",
    "        if dependecy_task_number.empty:\n",
    "\n",
    "            break\n",
    "\n",
    "        elif dependecy_task_number.iloc[0] == None and len(dependecy_task_number)==1:\n",
    "\n",
    "            break\n",
    "\n",
    "    sTask_number_list=\"'\"+\"','\".join(task_number_list)+\"'\"\n",
    " \n",
    "    Already_present_records=pd.read_sql(f'''select Task_Number from Credit_GPT.dbo.Task_Processing where Webtop_ID='{webtop_id}' and \n",
    "\n",
    "                                        Task_Number in ({sTask_number_list})''',conn)\n",
    "\n",
    "    set_Already_present_records=set(Already_present_records['Task_Number'])\n",
    "\n",
    "    set_task_number_list=set(task_number_list)\n",
    "\n",
    "    set_new_tasks_to_insert=set_task_number_list-set_Already_present_records\n",
    "\n",
    "    sNew_tasks_to_insert=\"'\"+\"','\".join(set_new_tasks_to_insert)+\"'\"\n",
    "\n",
    "    cur.execute(f'''Insert Into Credit_GPT.dbo.Task_Processing \n",
    "\n",
    "                    select '{work_id}','{webtop_id}', Task_Number,Task_Name ,'New',getdate(),Null,Null,0,Null,Null,'{process_name}'\n",
    "\n",
    "                    from Credit_GPT.dbo.Task_Master where Task_Number in ({sNew_tasks_to_insert})\n",
    "\n",
    "                ''')\n",
    "    cur.execute(f'''\n",
    "                INSERT INTO [Credit_GPT].dbo.Customer_Demog_Detail   (Webtop_ID)\n",
    "                VALUES ('{webtop_id}')\n",
    "                INSERT INTO [Credit_GPT].dbo.Verifications_Detail   (Webtop_ID)\n",
    "                VALUES ('{webtop_id}')\n",
    "                INSERT INTO [Credit_GPT].dbo.Offer_Detail (Webtop_ID)\n",
    "                VALUES ('{webtop_id}')\n",
    "                INSERT INTO [Credit_GPT].dbo.Loan_Detail (Webtop_ID)\n",
    "                VALUES ('{webtop_id}')\n",
    "                INSERT INTO [Credit_GPT].dbo.Credit_Headers (Webtop_ID)\n",
    "                VALUES ('{webtop_id}');\n",
    "                ''')\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    # return task_number_list,set_Already_present_records,set_new_tasks_to_insert,\n",
    " \n",
    "print(task_insertion('12ea4c','074PZ8600310','Bureau Analysis','ReportCreation'))\n",
    " \n",
    " \n",
    "    \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Innovation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
